[
  {
    "objectID": "In-class exercise 1/in-class_ex1.html",
    "href": "In-class exercise 1/in-class_ex1.html",
    "title": "In class ex1",
    "section": "",
    "text": "load below 3 packages :\n\ntmap: for the thematic mapping\nsf: for s-geospatial data handling\ntidyverse: for non-spatial data handling\n\n\npacman::p_load(tmap,sf,tidyverse)"
  },
  {
    "objectID": "In-class exercise 1/in-class_ex1.html#getting-started",
    "href": "In-class exercise 1/in-class_ex1.html#getting-started",
    "title": "In class ex1",
    "section": "",
    "text": "load below 3 packages :\n\ntmap: for the thematic mapping\nsf: for s-geospatial data handling\ntidyverse: for non-spatial data handling\n\n\npacman::p_load(tmap,sf,tidyverse)"
  },
  {
    "objectID": "In-class exercise 1/in-class_ex1.html#importing-the-od-data",
    "href": "In-class exercise 1/in-class_ex1.html#importing-the-od-data",
    "title": "In class ex1",
    "section": "Importing the OD data",
    "text": "Importing the OD data\nFirstly, we will import the Passenger Volume by origin destination bus stop dataset downloaded from LTA Datamall by using ‘read_csv()’ of readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n\naugust\n\nodbus$ORIGIN_PT_CODE &lt;-\nas.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;-\nas.factor(odbus$DESTINATION_PT_CODE)\n\n\n#| eval:false\n\norigtrip_7_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 7 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nbusstop &lt;- st_read(dsn = \"Data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kekekay\\ISSS624\\In-class exercise 1\\Data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MPSZ-2019\") %&gt;%\nst_transform(crs=3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\kekekay\\ISSS624\\In-class exercise 1\\Data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26..."
  },
  {
    "objectID": "In-class_2/In_class2.html",
    "href": "In-class_2/In_class2.html",
    "title": "In_class_2",
    "section": "",
    "text": "Import packages\n\npacman::p_load(sf, tmap, sfdep,tidyverse, knitr,plotly)\n\nImport attribute files and join\n\ngetwd() \n\n[1] \"C:/kekekay/ISSS624/In-class_2\"\n\nhunan &lt;- st_read(\"data/geospatial\",layer = \"Hunan\") \n\nReading layer `Hunan' from data source \n  `C:\\kekekay\\ISSS624\\In-class_2\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 &lt;- read.csv(\"data/aspatial/Hunan_2012.csv\") \n\nsfdep - time cube\n\nhunan_GDPPC&lt;- left_join(hunan,hunan2012)%&gt;% select(1:4,7,15)\n\nJoining with `by = join_by(County)`\n\n\n1st - spatial layer\n2nd - non spatial layer\n\n\n\nwm_q &lt;- hunan_GDPPC %&gt;%   \n  mutate(nb = st_contiguity(geometry),          \n         wt = st_weights(nb, \n                         style = \"W\"),          \n         .before = 1)"
  },
  {
    "objectID": "In-class_2/In_class2.html#deriving-contiguity-weights-queens-method",
    "href": "In-class_2/In_class2.html#deriving-contiguity-weights-queens-method",
    "title": "In_class_2",
    "section": "",
    "text": "wm_q &lt;- hunan_GDPPC %&gt;%   \n  mutate(nb = st_contiguity(geometry),          \n         wt = st_weights(nb, \n                         style = \"W\"),          \n         .before = 1)"
  },
  {
    "objectID": "In-class_2/inclass_ex2_v2.html",
    "href": "In-class_2/inclass_ex2_v2.html",
    "title": "In-class Exercise 2:",
    "section": "",
    "text": "pacman::p_load(tmap,sf,sfdep,tidyverse,knitr, plotly,zoo,kendall)"
  },
  {
    "objectID": "In-class_2/inclass_ex2_v2.html#getting-started",
    "href": "In-class_2/inclass_ex2_v2.html#getting-started",
    "title": "In-class Exercise 2:",
    "section": "",
    "text": "pacman::p_load(tmap,sf,sfdep,tidyverse,knitr, plotly,zoo,kendall)"
  },
  {
    "objectID": "In-class_2/inclass_ex2_v2.html#the-data",
    "href": "In-class_2/inclass_ex2_v2.html#the-data",
    "title": "In-class Exercise 2:",
    "section": "The Data",
    "text": "The Data\n\nImporting the data\n\nHunan, a geospatial data set in ESRI shapefile format\nHunan_2012, an attribute data set in csv format\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\kekekay\\ISSS624\\In-class_2\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nCombine both data frames\n\nhunan_GDPPC &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "In-class_2/inclass_ex2_v2.html#computing-contiguity-spatial-weights",
    "href": "In-class_2/inclass_ex2_v2.html#computing-contiguity-spatial-weights",
    "title": "In-class Exercise 2:",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nUse poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. Note: A “queen” argument taking TRUE/FALSE option can be passed. Default is set to TRUE.\n\nComputing (QUEEN) contiguity based neighbours\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb, style = \"W\"),\n         .before = 1)"
  },
  {
    "objectID": "In-class_2/inclass_ex2_v2.html#global-spatial-autocorrelation",
    "href": "In-class_2/inclass_ex2_v2.html#global-spatial-autocorrelation",
    "title": "In-class Exercise 2:",
    "section": "Global Spatial Autocorrelation",
    "text": "Global Spatial Autocorrelation\nCompute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\nComputing local Moran’s I\nLocal Moran’s I of GDPPC at country level\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before = 1) %&gt;%\n  unnest(local_moran)"
  },
  {
    "objectID": "In-class_2/inclass_ex2_v2.html#time-series-cube",
    "href": "In-class_2/inclass_ex2_v2.html#time-series-cube",
    "title": "In-class Exercise 2:",
    "section": "Time Series Cube",
    "text": "Time Series Cube\n\nGDPPC &lt;- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")\n\n\nGDPPC_st &lt;- spacetime(GDPPC, hunan, \n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\nis_spacetime_cube(GDPPC)\n\n[1] FALSE\n\n\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb,geometry,\n                                  scale = 1,\n                                  alpha=1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")"
  },
  {
    "objectID": "In-class_2/inclass_ex2_v2.html#computing-gi",
    "href": "In-class_2/inclass_ex2_v2.html#computing-gi",
    "title": "In-class Exercise 2:",
    "section": "Computing Gi*",
    "text": "Computing Gi*\n\ngi_stars &lt;- GDPPC_nb %&gt;%\n  group_by(Year) %&gt;%\n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;%\n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_2/inclass_ex2_v2.html#emerging-hot-spots",
    "href": "In-class_2/inclass_ex2_v2.html#emerging-hot-spots",
    "title": "In-class Exercise 2:",
    "section": "Emerging Hot Spots",
    "text": "Emerging Hot Spots\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st,\n  .var = \"GDPPC\",\n  k = 1,\n  nsim = 99\n)\n\nhunan_ehsa &lt;- hunan %&gt;%\n  left_join(ehsa,\n            by = join_by(County==location))\n\n\nVisualising the distribution of EHSA classes\n\nehsa_sig &lt;- hunan_ehsa %&gt;%\n  filter(p_value &lt; 0.05)\n\ntmap_mode(\"plot\")\ntm_shape(hunan_ehsa) +\n  tm_polygons +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") +\n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html",
    "title": "Hands-on_Ex3",
    "section": "",
    "text": "to import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desire lines data."
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html#objectives",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html#objectives",
    "title": "Hands-on_Ex3",
    "section": "",
    "text": "to import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desire lines data."
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html#getting-started",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html#getting-started",
    "title": "Hands-on_Ex3",
    "section": "Getting Started",
    "text": "Getting Started\n\nsf for importing, integrating, processing and transforming geospatial data.\ntidyverse for importing, integrating, wrangling and visualising data.\ntmap for creating thematic maps.\n\n\npacman::p_load(tmap, sf, DT, stplanr,\n               performance,\n               ggpubr, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html#preparing-the-flow-data",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html#preparing-the-flow-data",
    "title": "Hands-on_Ex3",
    "section": "Preparing the Flow Data",
    "text": "Preparing the Flow Data\n\nImporting the OD data\n\ngetwd()\n\n[1] \"C:/kekekay/ISSS624/Hands-on_Ex3\"\n\nodbus &lt;- read_csv(\"Data/aspatial/origin_destination_bus_202310.csv\")\n\nRows: 5694297 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): YEAR_MONTH, DAY_TYPE, PT_TYPE, ORIGIN_PT_CODE, DESTINATION_PT_CODE\ndbl (2): TIME_PER_HOUR, TOTAL_TRIPS\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE) \n\n\n\nExtracting the study data\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n`summarise()` has grouped output by 'ORIGIN_PT_CODE'. You can override using\nthe `.groups` argument.\n\n\n\ndatatable(odbus6_9)\n\nWarning in instance$preRenderHook(instance): It seems your data is too big for\nclient-side DataTables. You may consider server-side processing:\nhttps://rstudio.github.io/DT/server.html\n\n\n\n\n\n\n\n\nwrite_rds(odbus6_9, \"Data/rds/odbus6_9.rds\")\n\n\nodbus6_9 &lt;- read_rds(\"Data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html#working-with-geospatial-data",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html#working-with-geospatial-data",
    "title": "Hands-on_Ex3",
    "section": "Working with Geospatial Data",
    "text": "Working with Geospatial Data\n\nImporting geospatial data\n\nbusstop &lt;- st_read(dsn = \"Data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\kekekay\\ISSS624\\Hands-on_Ex3\\Data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nmpsz &lt;- st_read(dsn = \"Data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\kekekay\\ISSS624\\Hands-on_Ex3\\Data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26..."
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html#geospatial-data-wrangling",
    "title": "Hands-on_Ex3",
    "section": "Geospatial data wrangling",
    "text": "Geospatial data wrangling\n\nCombining Busstop and mpsz\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\n\ndatatable(busstop_mpsz)\n\n\n\n\n\n\n\nwrite_rds(busstop_mpsz, \"Data/rds/busstop_mpsz.rds\")  \n\n\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nWarning in left_join(odbus6_9, busstop_mpsz, by = c(ORIGIN_PT_CODE = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 25632 of `x` matches multiple rows in `y`.\nℹ Row 673 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\nod_data &lt;- unique(od_data)\n\n\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\nWarning in left_join(od_data, busstop_mpsz, by = c(DESTIN_BS = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 167 of `x` matches multiple rows in `y`.\nℹ Row 672 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\nod_data &lt;- unique(od_data)\n\n\nod_data &lt;- od_data %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\n`summarise()` has grouped output by 'ORIGIN_SZ'. You can override using the\n`.groups` argument.\n\n\n\nwrite_rds(od_data, \"Data/rds/od_data.rds\")\n\n\nod_data &lt;- read_rds(\"Data/rds/od_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html#visualising-spatial-interaction",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html#visualising-spatial-interaction",
    "title": "Hands-on_Ex3",
    "section": "Visualising Spatial Interaction",
    "text": "Visualising Spatial Interaction\n\nRemoving intra-zonal flows\n\nod_data1 &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]\n\n\n\nCreating desire lines\n\nflowLine &lt;- od2line(flow = od_data1, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nCreating centroids representing desire line start and end points.\n\n\n\n\nVisualising the desire lines\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length\n\n\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length"
  },
  {
    "objectID": "Hands-on Ex1/Hands-on_1.html",
    "href": "Hands-on Ex1/Hands-on_1.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, i learned how to import and wrangle geospatial data in using appropriate R packages."
  },
  {
    "objectID": "Hands-on Ex1/Hands-on_1.html#overview",
    "href": "Hands-on Ex1/Hands-on_1.html#overview",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, i learned how to import and wrangle geospatial data in using appropriate R packages."
  },
  {
    "objectID": "Hands-on Ex1/Hands-on_1.html#getting-started",
    "href": "Hands-on Ex1/Hands-on_1.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Getting Started",
    "text": "Getting Started"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex3/Data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex3/Data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class exercise 1/Data/geospatial/MPSZ-2019.html",
    "href": "In-class exercise 1/Data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_2/In_class2-EHSA.html",
    "href": "In-class_2/In_class2-EHSA.html",
    "title": "In_class_2",
    "section": "",
    "text": "Import packages\n\npacman::p_load(sf, tmap, sfdep,tidyverse, knitr,plotly)\n\nImport attribute files and join\n\ngetwd() \n\n[1] \"C:/kekekay/ISSS624/In-class_2\"\n\nhunan &lt;- st_read(\"data/geospatial\",layer = \"Hunan\") \n\nReading layer `Hunan' from data source \n  `C:\\kekekay\\ISSS624\\In-class_2\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 &lt;- read.csv(\"data/aspatial/Hunan_2012.csv\") \n\nsfdep - time cube\n\nhunan_GDPPC&lt;- left_join(hunan,hunan2012)%&gt;% select(1:4,7,15)\n\nJoining with `by = join_by(County)`\n\n\n1st - spatial layer\n2nd - non spatial layer\n\n\n\nwm_q &lt;- hunan_GDPPC %&gt;%   \n  mutate(nb = st_contiguity(geometry),          \n         wt = st_weights(nb, \n                         style = \"W\"),          \n         .before = 1)"
  },
  {
    "objectID": "In-class_2/In_class2-EHSA.html#deriving-contiguity-weights-queens-method",
    "href": "In-class_2/In_class2-EHSA.html#deriving-contiguity-weights-queens-method",
    "title": "In_class_2",
    "section": "",
    "text": "wm_q &lt;- hunan_GDPPC %&gt;%   \n  mutate(nb = st_contiguity(geometry),          \n         wt = st_weights(nb, \n                         style = \"W\"),          \n         .before = 1)"
  },
  {
    "objectID": "In-class_2/In_class2-EHSA.html#computing-local-morans-i",
    "href": "In-class_2/In_class2-EHSA.html#computing-local-morans-i",
    "title": "In_class_2",
    "section": "Computing local Moran’s I",
    "text": "Computing local Moran’s I\nuse local_moran() of sfdep package to compute local moran’s I of GDPPC at county level\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran( \n    GDPPC, nb, wt, nsim = 99), \n    .before = 1) %&gt;% \n  unnest(local_moran)"
  },
  {
    "objectID": "In-class_2/In_class2-EHSA.html#time-series-cube",
    "href": "In-class_2/In_class2-EHSA.html#time-series-cube",
    "title": "In_class_2",
    "section": "Time Series Cube",
    "text": "Time Series Cube\n\nGDPPC &lt;- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")\n\nRows: 1496 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): County\ndbl (2): Year, GDPPC\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nGDPPC_st &lt;- spacetime(GDPPC, hunan, \n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\nis_spacetime_cube(GDPPC)\n\n[1] FALSE\n\n\n\npacman::p_load(zoo,Kendall)\n\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE\n\n\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb =include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb,geometry,\n                                  scale = 1,\n                                  alpha=1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wt = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\nComputing GI*\n\ngi_stars &lt;- GDPPC_nb %&gt;%\n  group_by(Year) %&gt;%\n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;%\n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_2/In_class2-EHSA.html#visualising-the-distribution-of-ehsa-classes",
    "href": "In-class_2/In_class2-EHSA.html#visualising-the-distribution-of-ehsa-classes",
    "title": "In_class_2",
    "section": "Visualising the distribution of EHSA classes",
    "text": "Visualising the distribution of EHSA classes\n\n#install.packages(\"Kendall\", repos = \"https://cloud.r-project.org\")\nlibrary(Kendall)\n\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st,\n  .var = \"GDPPC\",\n  k = 1,\n  nsim = 99\n)\n\nhunan_ehsa &lt;- hunan %&gt;%\n  left_join(ehsa,\n            by = join_by(County==location))\n\n\nehsa_sig &lt;- hunan_ehsa %&gt;%\n  filter(p_value &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hunan_ehsa) +\n  tm_polygons +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") +\n  tm_borders(alpha = 0.4)"
  }
]